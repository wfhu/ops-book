# 运维能力第一阶段--满足业务需求

---

## 一：满足业务对资源需求的能力

---

业务对资源的合理需求必须得到满足，保证质量和效率的同时需要控制好成本。

主要从以下三个方面考虑：

* 效率：同样的资源需求，多久能得到满足，一个月、一个星期、一天或者2小时，对业务部门来说是有质的区别的。

* 质量：给出来的资源质量如何？是否符合预期？前后一致性是否有保障？

* 成本：成本可以增长，但必须是可控的。

#### 1.1、使用物理IDC机房，租赁机柜和带宽，自己购买服务器

**优势**

* 机器配置和网络架构更加自主可控
* 物理隔离更安全
* 可选择部署地域更广
* 性能可预期
* 上规模时成本有优势

**劣势**

* 交付周期长
* 防攻击抵御能力差
* 可伸缩性比较差

**选择物理机房的技术准备**

* 远程管理卡和远程管理网络

* 系统安装服务，如FAI、PXE、Cobbler等

* 网络上联出口高可用

* 服务器网卡设置bonding

* 公网互联互通，考虑出口线路

#### 1.2、直接租赁专用物理服务器

**优势**

* 交付周期相对较短，一般在几小时或者几日内能交付
* 具备一定程度的可伸缩性，一般按月租赁，退租方便

**劣势**

* 成本偏高
* 知名的厂商有：Softlayer、RackSpace、NTT等

#### 1.3、选择传统物理IDC机房方法

**看机房建设标准**

比如国内机房有所谓三星、四星、五星机房，国外有Tier-2，Tier-3，Tier-4等，理论上级别越高机房越可靠。

**看机房地理位置和建筑外形**

优先选择地理位置在郊区、独栋的专业IDC机房，这些一般比处在市中心、高楼大厦中划分某几层用来做IDC的要好。

**选择知名的IDC机房供应商**

比如选择Equinix、Digital Realty、NTT等提供的机房，一般机房本身的品质有保障。

这里可以重点关注一下Equinix机房，他主推的IBX服务，机房质量和网络的互联互通都比较好。

更多关于IDC选择的标准，可以参考[UptimeInstitute](https://uptimeinstitute.com/)。

#### 1.4、选择云服务厂商

云服务厂商用得越来越多，我们也可以充分利用其优势和特点，帮助我们支持好业务的运行。

**优势**

* 资源和服务获取速度快
* 可伸缩性强
* 降低服务使用的技术门槛

**劣势**

* 安全不可控
* 性能不可控
* 排查问题存在黑盒

**AWS**

云服务领域的绝对老大

使用过的特色服务：

Lambda：无服务器运行环境

Athena： Hive as a Service

S3：近乎无限可扩展的对象存储服务

需要注意的地方：

AccessKey的安全性要注意，不建议使用，一旦泄露影响非常大；建议使用IAM和MFA管理用户权限

EC2存储区分持久存储和临时存储，临时存储在关机-再开机后数据全部丢失

EC2实例默认不能转发数据包，需要后台设置运行转发

注意各种资源的购买限制，如果没规划好，突发需求可能不能马上得到满足

**阿里云**

国内云服务的领导者

使用过的特色服务：

高速通道

需要注意的地方：

管理后台用户体验极差，一般建议自己通过API自定义UI，但是API很不健全

ECS实例里面有自动运行阿里的多个agent，安全性和可靠性有待考量

#### 1.5、CDN服务

一般来讲，现在的企业都不会自己建设CDN，一般选择外包给专业的CDN服务商。

**Akamai**

老牌CDN服务商，全球CDN及相关服务的老大，绝对的技术领头羊和市场领导者

优点

网络覆盖好，接入ISP达到1700+，用户体验好，防攻击能力强，可配置性极强

缺点

服务较差，费用比较贵，后台配置麻烦，刷新缓存\(Purge\)比较慢

**AWS CloudFront**

亚马逊云服务的一个产品，近年来表现不错，持续扩张中

优点

后台配置简单，即开即用，和AWS其他服务结合紧密

缺点

并非专业的CDN厂商，节点覆盖不多，全球节点不到100个，可配置性较差

**CloudFlare**

这些年新出的一个CDN厂商，大量使用anycast技术，主打高性能、低价和防攻击，占领了大量中小企业市场

优点

费用较低，企业级套餐可能只有Akamai的三分之一价格；配置比较简单方便；刷新缓存\(Purge\)极快

缺点

回源模式单一，不支持源站+子目录形式回源；

##### CDN管理需要考虑的问题：

带宽和流量异常告警

源站的高可用和上传访问控制

#### 1.6、DNS域名解析服务

DNS服务往往容易被人忽略，但是其实DNS服务是非常核心的服务，也是比较脆弱的服务，容易成为攻击的目标

**自建DNS服务**

安全性方面需要考虑一下问题：DDOS，DNS放大攻击，zone transfer访问控制，高可用

功能方面：智能DNS功能，分布式访问性能

**DNSPOD**

国内知名的DNS域名解析服务提供商，有免费版但不保证可用性，经常用来当小白鼠测试新功能；企业版比较不错，各种运营商线路以及国内外区分，基本满足国内业务的需求。

提供HTTP DNS服务，可有效避免DNS拦截。

**AWS Route53**

支持智能DNS，对海外国家/地区区分较好；有CNAME flatting等功能。

**Akamai FastDNS**

功能比较单一，没有智能DNS功能。

> 有一个问题：不支持同一个域名修改record类型，只能删除再添加，会导致服务短暂中断。如：www.mysite.com CNAME 到 mycdn.akam.net，需要修改成 A 记录并指向 IP 1.2.3.4，只能删除原有CNAMEA记录记录再重新添加，不能直接修改记录类型。

#### 1.7、容量（能力）管理

从ITIL中的Capacity managememt而来，是资源规划的是否有效的方法。

容量管理主要需要考虑一下几个方面：

**业务预算搜集**

* 业务资源趋势判断
* 新增业务资源搜集

**资源池管理**

* 业务日常资源
* 业务突发资源
* 特殊故障资源

## 二：满足业务发布/变更的能力

---

运维不能成为阻挡业务发布和变更的障碍

* 效率: 自助操作
* 质量: 流程化/规范化

### 2.1、发布系统

无论是自己开发还是使用开源工具，一套可以交付给业务人员进行操作的发布系统，确实是必须的，不然运维就会被日常需求困住收缴，而响应时间也会影响业务的效率。

比如业务想更新一下Web的代码，叫运维操作的话，运维也只是一个劳动力而已，操作本身没有任何体现价值的地方。如果把同样的工作做到发布系统里面，设定好相应的流程和权限，让相关人员自己操作，大家都满意。

### 2.2、持续集成和持续交付

持续集成工具，对于减少运维和开发的重复劳动，提高工作效率能起到非常重要的作用，还能保证交付质量。比如从代码管理工具（SCM）中的代码提交、代码单元测试、功能测试、打包、推送相关环境都做成自动的，对于效率的提高可想而知。

一般开发团队都有自己的CICD工具和流程，运维可以考虑把CICD应用到测试环境的管理上来。

常见开源工具：

Jenkins

Spinnaker

### 2.3、作业系统

作业系统，或者叫事件驱动系统\(Event-Driven Automation\)，能够基于事件、时间等自动或者手动进行固定化流程的操作。

重点提升的是质量和效率：把可以交给别人做的事情放心地交出去，把经常需要做的事件固化下来。

比如我们要重启某些服务，可能需要按一定的顺序操作，那么我们可以把这个工作固化成一个作业交付给相应的业务人员。对方需要做操作的时候，可以直接在作业系统上点击操作，运维完全不用参与，提升质量和效率。又或者一些常见的操作，比如清理日志或者获取机器信息，可以把这些固化到作业系统，需要的时候只需一键点击，不用担心前后操作的不一致。

常见开源工具：

RUNDECK

StackStorm

## 三：快速获取业务相关信息的能力

---

有异常能发现，能快速获取想要的数据，能快速定位问题

1. 效率: 自助化/可视化/用户体验 基础设施既代码 配置管理 文档

2. 质量: 多维度监控覆盖

3. 屏蔽复杂度，给需要数据的部门/业务，提供统一的获取数据的接口

**基础监控**

把最基础的数据统一搜集起来，无论是什么类型的服务器，无论运行什么服务，这些都是有价值的、或者都需要查看的数据。可以做成统一的模板。

通过salt+zabbix+python+graphite+grafana，基本可以把一套基础监控的环境自动搭建和维护起来。![](/assets/dog01.png)

**网络监控**

对网络质量的监控同样非常重要，对延迟、丢包的变化需要特别注意；对业务服务对象所在地区的网络情况要区别对待，比如四川麻将业务，则重点关注川渝地区。

基于smokeping+python+graphite+grafana，数据搜集、上报、展示一条龙全部解决。

![](/assets/dog-network-home.png)![](/assets/dog-network-brief.png)![](/assets/dog-network-detail.png)

网络监控的痛点在于：如何获取稳定、可靠的目标监控点，我有一些经验可以分享：

* 找当地排名靠前的网站的IP地址，比如通过Alexa按国家和地区查找。
* 查找当地公共的DNS服务器，这种一般很少变动。
* 通过traceroute用户的真实IP地址，监控中间出现频率较高的公共节点，这种一般是ISP的网关或者路由设备，比较稳定。

**应用基础指标监控**

业务在运行中，必然有一些技术指标需要搜集，比如php请求数、haproxy连接数、缓存命中率等等。这些数据都需要根据业务的具体情况进行监控。

使用Prometheus+grafana+相应的exporter或者python脚本自定义的的上报内容，可以很好地实现。

比如我们的php应用监控页面：

![](/assets/dog-php-fpm.png)

**应用性能监控**

Application Performance Monitor\(APM\)

做APM是深入优化业务的一种关键技术，可以从业务内部逻辑上做很多的数据统计，对于排查问题以及优化性能起到非常大的帮助。

我们使用了Statsd+Graphite+Grafana的方案，业务端插入相应语言的上报代码，对于函数的调用次数和延迟做到实时监控。使用Statsd的方案，主要是因为它基于UDP上报，几乎对性能不产生影响，上报异常也不会对业务产生不良影响或影响很小。

![](/assets/dog-APM-1.png)

经过有针对性的优化后，性能明显提升：

![](/assets/dog-APM-02.png)

**业务指标监控**

比如在线人数、订单数量、比赛场次、充值金额等等

**日志管理和分析**

ELK系统

**调用追踪系统**

OpenTrace

OpenZipkin

-工作案例：

1. 引入WIKI工具，规范工作文档
2. 引入puppet/saltstack工具维护线上环境配置，环境可重现
3. zabbix/smokeping/prometheus/graphite/grafana多维度监控和可视化
4. 集群基础设施引入CloudFormation/Terraform等工具管理

## 四：满足业务对可用性和稳定性要求的能力

默认一切都是不可靠的，都是会出故障的

（跑的好不好，现在、未来、持久地跑好）

1. 质量: 去单点 故障自愈能力 安全规范和扫描
2. 效率: 预案和演练

架构高可用（去单点）

服务自动恢复

横向可扩展性

安全、可控、可预期

-核心能力/概念

：知识/故障管理，可扩展性，可靠性和运行效率

-工作案例：

1. WEB层全面去单点
2. 引入Docker集群，自动故障漂移/恢复
3. 例行强制重启任意一台业务机，确保高可用能力
4. 引入Nessus/OpenVAS例行扫描，发现对外开放的免密的redis/memcache等

## 五、快速部署和故障恢复的能力

故障演练和预案

基础设施即代码（Infrastructure as Code）

CloudFormation

TerraForm

配置管理工具

Ansible

SaltStack

系统镜像和模板

备份与恢复

不可变基础设施

