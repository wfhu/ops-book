经验分享--排查问题案例及优化方案

1、扑克头像线下物理机架构上AWS云，计算、存储分离，按需，高可用、未来扩张方便。

2、德州扑克 法国、波兰地区，少量用户反馈访问不了，经过查询，是在偏僻小镇，CDN供应商从AWS换成Akamai后完美解决。

3、大公司NAT网关，出口都是一个IP，同时我们的服务器端的tcp\_tw\_recycle（服务器端配置）/timestamp（服务器端配置）设置为1，导致该公司的某些用户经常反馈连接不上，reset等。关掉这些配置就好了。

4、hadoop集群，默认自动du，导致负载奇高。

5、Hive存储格式，按日期分片、parquet格式压缩和列存储，大幅提升效率。

6、提前准备了机器做迁服，结果没改状态，被其他同事用去做正式服务了，结果这个机器回来就弄去重启和初始化了，导致业务中断。优化方案：重装系统流程更严谨，需要业务人员和上级审核确认；空闲服务器监控负载；更深入一点的，监控进程和端口白名单；文档记录，提高意识，防止重复发生。

7、地方棋牌lua代码连接redis/mysql过高；BPT业务server占用过多内存-

&gt;

导致SWAP-

&gt;

导致IO和CPU和负载均升高，中间只差了2分钟；地方棋牌业务逻辑梳理，用户登录信息从保存在MySQL修改到保存进redis；（优化方案：业务上线前技术方案评审）

8、德州扑克web-

&gt;

mserver-

&gt;

mongodb排错过程：机器间丢包情况，mserver调用过程埋点，获取具体的延迟数据，排查出是mongodb反应慢-

&gt;

反馈给阿里云排查，是宿主机存在问题。（全链路监控的重要性）

9、监控数据是真的问题（API获取的监控数据粒度是分钟级别，而阿里云后台控制是秒级，导致我们这边看见都是正常的，但是实际已经开始限制用户/玩家的流量了）

10、hadoop用户在hadoop用户的.bashrc\(或者是.profile\)文件下写了sudo su - hadoop，造成hadoop用户登录死循环，通过监控进程数触发报警及时解决。

11、泰国mongodb机器故障，为了保留原有内网IP地址，两台机器呼唤IP后，需要保留的IP时好时坏，怀疑是ARP缓存等原因造成的。

12、监控平稳业务数据变化趋势，发现链接数持续上升，发现代码内未能关闭已打开的链接，导致链接数持续上升。（发现policy server版本过老，存在句柄溢出，升级版本后正常）

13、通过监控time wait数量，分析出进程建立链接数的频率，最高每秒八百次新建链接，让业务优化代码，增加厂链接，中间添加访问代理层，下降到几十次每秒。链接复用。

